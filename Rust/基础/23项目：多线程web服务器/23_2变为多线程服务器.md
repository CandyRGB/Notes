## 变为多线程服务器
目前服务器会依次处理每一个请求，意味着它在完成第一个连接的处理之前不会处理第二个连接。可以理解为*队列*，只有头可以取出，当队列的头不动时，队列就堵塞了。

### 模拟慢请求
```rust
use std::{
    fs,
    io::{prelude::*, BufReader},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let (status_line, filename) = match request_line.as_str() {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));  // 模拟慢请求
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    // --snip--
}
```
当路径为`/sleep`时，等待 5 秒再响应。保存并运行，先访问`localhost:7878/sleep`，然后快速访问`localhost:7878`，会发现后访问的页面被阻塞了，等待`localhost:7878/sleep`加载完毕后`localhost:7878`才开始加载，不过由于加载的很快，几乎是同时完毕的。
有多种技术可以用来避免所有请求都排在慢请求之后；我们将要实现的一个便是线程池。

### 使用线程池改善吞吐量
**线程池**（thread pool）是一组预先分配的等待或准备处理任务的线程。当程序收到一个新任务，线程池中的一个线程会被分配任务，这个线程就会离开线程池处理任务。这个线程处理任务的同时，线程池中的其它线程也可接收并处理任务。这个线程完成任务后，它会返回空闲线程池中等待处理新任务。

#### 为每个请求分配线程
```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        thread::spawn(|| {
            handle_connection(stream);
        });
    }
}
```
这最终会使系统崩溃，因为我们可以无限制的创建新线程，无法防止 DOOS 攻击。

#### 创建有限数量的线程
我们希望创建有限数量的新线程并且使用线程池：
```rust
// 无法运行
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);  // 表示创建了拥有4个线程的线程池

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        // 使用线程池上的 execute 替代 thread::spawn 执行线程
        pool.execute(|| {
            handle_connection(stream);
        });
    }
}
```

#### 构建 ThreadPool
同时在 lib\.rs 下创建`ThreadPool`及它的方法，使`main.rs`中没有错误：
```rust
pub struct ThreadPool;

impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        ThreadPool
    }
    pub fn execute<F>(&self, f: F)
    where
    F: FnOnce() + Send + 'static,
    {

    }
}
```
由于`ThreadPool::execute`替代的是`thread::spawn`，我们可以仿照它的签名来写`execute`的函数签名。
`thread::spawn`的签名：
```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```
相对于`thread::spawn`，我们不需要返回值，不需要使用泛型`T`。`ThreadPool::execute`的签名：
```rust
pub fn execute<F>(&self, f: F)
where
    F: FnOnce() + Send + 'static,
```

#### 在 new 中验证池中线程数量并添加文档
```rust
impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);  // 线程池中的线程至少有一个

        ThreadPool
    }

    // --snip--
}
```
这里也用文档注释为 ThreadPool 增加了一些文档。尝试运行`cargo doc --open`并点击 ThreadPool 结构体就可以查看生成的 new 的文档。

#### 分配空间以储存线程
回看`thread::spawn`的签名，它返回了一个`JoinHandle<T>`，它是一个拥有线程句柄的类型，因此我们可以用它存储线程。
传递给线程池的闭包会处理连接并不返回任何值，我们对`JoinHandle<T>`中的参数不感兴趣，这时可以使用`()`作为参数类型。
```rust
use std::thread;

pub struct ThreadPool {
    threads: Vec<thread::JoinHandle<()>>,
}
```
```rust
impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        // Vec::with_capacity: 按 size 创建一个 size 容量的 empty vector
        let mut threads = Vec::with_capacity(size);

        for _ in 0..size {
            // create some threads and store them in the vector
        }

        ThreadPool { threads }
    }
    // --snip--
}
```

#### 使用 Worker 负责管理单个线程
想象一下：`ThreadPool`是地铁的售票处，`Worker`是各个售票窗口的员工，拥有`id`标识，`thread`是员工的服务状态。有空闲窗口时，人将优先去空闲窗口排队。
因此，我们可以这样定义`Worker`：
```rust
struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize) -> Worker {
        let thread = thread::spawn(|| {});
        Worker { id, thread }
    }
}
```
重新定义`ThreadPool`并完善代码：
```rust
pub struct ThreadPool {
    workers: Vec<Worker>,
}

impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers }
    }
    // --snip--
}
```

#### 使用信道向线程发送请求
目前，传递给`thread::spawn`的闭包完全没有做任何工作。我们希望`Worker`可以从`ThreadPool`接收并处理任务。
这里使用信道来充当任务队列：`execute`将通过`ThreadPool`向其中线程正在寻找工作的`Worker`实例发送任务。
1. ThreadPool 会创建一个信道并作为发送者。
2. 每个 Worker 将会作为接收者。
3. 新建一个 Job 结构体来存放用于向信道中发送的闭包。
4. execute 方法会在发送者发出期望执行的任务。
5. 在线程中，Worker 会遍历接收者并执行任何接收到的任务。
```rust
use std::{sync::mpsc, thread};

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();   // 信道

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, receiver));// 错误：只能有一个接收者
        }

        ThreadPool { workers, sender }
    }
    // --snip--
}

struct Job;

// --snip--

impl Worker {
    fn new(id: usize, receiver: mpsc::Receiver<Job>) -> Worker {
        let thread = thread::spawn(|| {
            receiver;
        });

        Worker { id, thread }
    }
}


```
我们希望能共享`receiver`，那么就需要对它进行原子引用，实现互斥访问。
```rust
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};
// --snip--

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver)); // 多线程共享 Mutex<T>

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    // --snip--
}

// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        // --snip--
    }
}
```
Job 结构体仅用来存放用于向信道中发送的闭包，因此不使用结构体，而使用类型别名：
```rust
type Job = Box<dyn FnOnce() + Send + 'static>;
```
闭包不是固定大小，故使用智能指针`Box<>`。
然后实现`execute`让它接收的闭包发送给`Worker`：
```rust
pub fn execute<F>(&self, f: F)
where
    F: FnOnce() + Send + 'static,
{
    let job = Box::new(f);
    self.sender.send(job).unwrap();
}
```
在请求端，我们需要闭包一直循环，向信道的接收端请求任务，并在得到任务时执行它们。
```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        // 创建好信道后每个员工都循环等待任务
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {} got a job; executing.", id);

            job();  // 执行闭包
        });

        Worker { id, thread }
    }
}
```
调用`recv`会阻塞当前线程，所以如果还没有任务，其会等待直到有可用的任务。`Mutex<T>`确保一次只有一个`Worker`线程尝试请求任务。
接收到任务后，互斥锁会立即释放，闭包开始执行，同时其他线程可以等待任务。